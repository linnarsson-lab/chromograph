{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Miscelaneous\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import loompy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "\n",
    "import chromograph\n",
    "from chromograph.peak_calling.utils import *\n",
    "from chromograph.pipeline.utils import *\n",
    "from chromograph.plotting.marker_plot import marker_plot\n",
    "from chromograph.plotting.peak_annotation_plot import plot_peak_annotation_wheel\n",
    "from chromograph.pipeline import config\n",
    "\n",
    "import cytograph as cg\n",
    "from cytograph.plotting.colors import colorize\n",
    "from cytograph.enrichment import FeatureSelectionByMultilevelEnrichment\n",
    "from cytograph.species import Species\n",
    "\n",
    "import fisher\n",
    "\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%H:%M:%S')\n",
    "\n",
    "config = config.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_m = '/fish/other_tmp/camiel_tmp/processed/GSE129785_scATAC-Hematopoiesis-All.mtx'\n",
    "file_b = '/fish/other_tmp/camiel_tmp/processed/GSE129785_scATAC-Hematopoiesis-All.cell_barcodes.txt.gz'\n",
    "file_p = '/fish/other_tmp/camiel_tmp/processed/GSE129785_scATAC-Hematopoiesis-All.peaks.txt.gz'\n",
    "\n",
    "mat = scipy.io.mmread(file_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "barcodes = pd.read_table(file_b)\n",
    "peaks = pd.read_csv(file_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_attrs = {k: np.array(barcodes[k]) for k in barcodes}\n",
    "del row_attrs\n",
    "\n",
    "for x in peaks['Feature']:\n",
    "    if 'row_attrs' not in locals():\n",
    "        row_attrs = {}\n",
    "        chrom, start, end = x.split('_')\n",
    "        row_attrs['ID'] = [f'{chrom}:{start}-{end}']\n",
    "        row_attrs['Chr'] = [chrom]\n",
    "        row_attrs['Start'] = [start]\n",
    "        row_attrs['End'] = [end]\n",
    "    else:\n",
    "        chrom, start, end = x.split('_')\n",
    "        row_attrs['ID'].append(f'{chrom}:{start}-{end}')\n",
    "        row_attrs['Chr'].append(chrom)\n",
    "        row_attrs['Start'].append(start)\n",
    "        row_attrs['End'].append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/fish/other_tmp/camiel_tmp/processed/Greenleaf_peaks.loom'\n",
    "\n",
    "loompy.create(filename, mat, row_attrs, col_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:39:35 INFO     Calculate coverage metrics\n",
      "19:39:41 INFO     Convert to CPMs\n",
      "19:39:44 INFO     Binarize peak matrix\n",
      "100%|██████████| 31/31 [00:26<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from chromograph.peak_analysis.utils import *\n",
    "\n",
    "filename = '/fish/other_tmp/camiel_tmp/processed/Greenleaf_peaks.loom'\n",
    "out_file = '/fish/other_tmp/camiel_tmp/processed/Greenleaf_peaks.agg.loom'\n",
    "\n",
    "agg_spec = {\n",
    "    \"Group\": \"tally\",\n",
    "    \"Clusters\": \"first\",\n",
    "    \"FRIP\": \"mean\",\n",
    "    \"depth\": \"mean\"\n",
    "}\n",
    "\n",
    "with loompy.connect(filename) as ds:\n",
    "    ds.ca.Clusters = np.array([int(x.strip('Cluster')) for x in ds.ca.Clusters])\n",
    "    ds.aggregate(out_file, None, \"Clusters\", \"sum\", agg_spec)\n",
    "    \n",
    "    with loompy.connect(out_file) as dsout:\n",
    "\n",
    "        logging.info('Calculate coverage metrics')\n",
    "        dsout.ca.Total = dsout.map([np.sum], axis=1)[0]\n",
    "        dsout.ra.NCells = dsout.map([np.sum], axis=0)[0]\n",
    "\n",
    "        ## Normalize peak counts by total fragments per cluster\n",
    "        logging.info('Convert to CPMs')\n",
    "        dsout.layers['CPM'] = div0(dsout[''][:,:], dsout.ca.Total * 1e-6)\n",
    "\n",
    "        ## Call positive and negative peaks for every cluster\n",
    "        dsout['binary'], dsout.ca['CPM_thres'] = KneeBinarization(dsout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_enhancers(ds, reference):\n",
    "    '''\n",
    "    '''\n",
    "    peak_list = BedTool([(ds.ra['Chr'][x], str(ds.ra['Start'][x]), str(ds.ra['End'][x]), str(ds.ra['ID'][x])) for x in range(len(ds.ra['Chr']))]).saveas()\n",
    "    enhancers = BedTool(reference)\n",
    "    peak_list = peak_list.intersect(enhancers, wa=True)\n",
    "    enh_peaks = [x[3] for x in peak_list]\n",
    "    Valid = [x in enh_peaks for x in ds.ra.ID]\n",
    "    \n",
    "    return np.array(Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "\n",
    "with loompy.connect(out_file) as dsagg:\n",
    "    selection = isolate_enhancers(dsagg, os.path.join(config.paths.ref, 'regions', f'enhancer.bed'))\n",
    "    logging.info('Finished isolating enhancers')\n",
    "    \n",
    "    Valids = []\n",
    "    binary = dsagg['CPM'][:,:] > threshold\n",
    "    ON = np.sum(binary[:,population], axis=1) > 0\n",
    "    Valids = np.logical_and(selection, ON > 0)\n",
    "    plt.figure()\n",
    "    plt.title(f'Valid: {np.sum(Valids)}')\n",
    "    plt.hist(ON[selection], bins= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48362"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X > 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chromograph (py3.7)",
   "language": "python",
   "name": "chromo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
