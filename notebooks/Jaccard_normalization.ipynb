{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import loompy\n",
    "import scipy.sparse as sparse\n",
    "import urllib.request\n",
    "import pybedtools\n",
    "import warnings\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import cytograph as cg\n",
    "from cytograph.decomposition import HPF\n",
    "from scipy.stats import poisson\n",
    "from cytograph.manifold import BalancedKNN\n",
    "from cytograph.metrics import jensen_shannon_distance\n",
    "from cytograph.embedding import tsne\n",
    "from cytograph.clustering import PolishedLouvain, PolishedSurprise\n",
    "from cytograph.plotting import manifold\n",
    "\n",
    "sys.path.append('/home/camiel/chromograph')\n",
    "from chromograph.plotting.QC_plot import QC_plot\n",
    "\n",
    "from umap import UMAP\n",
    "import sklearn.metrics\n",
    "from scipy.spatial import distance\n",
    "import community\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "from typing import *\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from pynndescent import NNDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "f = '/data/proj/scATAC/chromograph/build_20191206/Cerebellum.loom'\n",
    "outdir = '/data/proj/scATAC/chromograph/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617643, 17811)\n"
     ]
    }
   ],
   "source": [
    "ds = loompy.connect(f, mode='r+')\n",
    "print(ds.shape)\n",
    "blayer = '5kb_bins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = (ds.ra['Coverage'] > -2) & (ds.ra['Coverage'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560008, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ds[blayer][:,:]\n",
    "data = data[bins,:1000]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(outdir, \"Cerebellum.csv\"), data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import njit, prange\n",
    "# @njit(parallel=True)\n",
    "# def numba_parallel_jaccard(M):\n",
    "#     #here if first it is run with range, then it is very slow.\n",
    "#     #then one range is replaced with prange, then it crashes, and then to range again\n",
    "#     #and then it is fastest (3x faster than with prange)\n",
    "#     u, i = M.shape\n",
    "#     js = np.zeros((u,u))\n",
    "#     for i in prange(u):\n",
    "#         for j in range(u):\n",
    "#             v = (M[i]*M[j] > 0).sum()\n",
    "#             if v:\n",
    "#                 js[i,j] = v/((M[i] + M[j] > 0).sum())\n",
    "#             else: \n",
    "#                 js[i,j] = 0\n",
    "#     return js\n",
    "\n",
    "# t = []\n",
    "# for x in range(5):\n",
    "#     start = time.time()\n",
    "\n",
    "#     N = 100\n",
    "#     srt = ds.ca['Clusters'][:N].argsort()\n",
    "\n",
    "#     ini = numba_parallel_jaccard(np.array([[0,1], [1,0]]))\n",
    "#     js = numba_parallel_jaccard(data[:,:N].T)\n",
    "\n",
    "#     t.append(time.time() - start)\n",
    "#     print(time.time() - start)\n",
    "    \n",
    "# plt.imshow(js[srt,:][:,srt])    \n",
    "# print(f'mean {np.mean(t)} with st. dev: {np.std(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a507f6f91464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0msrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clusters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# @numba.jit(\"float32(float64[:], float64[:])\", nopython=True, cache=True)\n",
    "# @njit(parallel=True, cache=True)\n",
    "\n",
    "@njit(parallel=True, cache=True)\n",
    "def jaccard_sim(data) -> float:\n",
    "    \n",
    "    N = data.shape[1]\n",
    "    f = data.shape[0]\n",
    "    js = np.zeros((N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        v1 = data[:,i]\n",
    "        for j in range(i+1, N):\n",
    "            v2 = data[:,j]\n",
    "    \n",
    "            p = np.zeros(f)\n",
    "            qr = np.zeros(f)\n",
    "            for x in range(f):\n",
    "                if v1[x] > 0 and v2[x] > 0:\n",
    "                    p[x] = 1\n",
    "                elif v1[x] > 0 or v2[x] > 0:\n",
    "                    qr[x] = 1\n",
    "\n",
    "            sp = np.sum(p) \n",
    "            sqr = np.sum(qr)\n",
    "            js[i,j] = sp / (sp+sqr)\n",
    "            js[j,i] = js[i,j]\n",
    "            \n",
    "    return js\n",
    "\n",
    "# t = []\n",
    "# for x in range(1):\n",
    "#     start = time.time()\n",
    "\n",
    "#     N = 10\n",
    "#     srt = ds.ca['Clusters'][:N].argsort()\n",
    "\n",
    "#     js = jaccard_sim(data[:,:N])\n",
    "\n",
    "\n",
    "#     t.append(time.time() - start)\n",
    "#     print(time.time() - start)\n",
    "\n",
    "# plt.imshow(js[srt,:][:,srt])    \n",
    "# print(f'mean {np.mean(t)} with st. dev: {np.std(t)}')\n",
    "    \n",
    "N = 100\n",
    "\n",
    "srt = ds.ca['Clusters'][:N].argsort()\n",
    "js = jaccard_sim(data[:,:N])\n",
    "plt.imshow(js[srt,:][:,srt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.sum(data, axis=0)\n",
    "P = C / data.shape[0]\n",
    "\n",
    "E = np.zeros([N,N])\n",
    "\n",
    "for i in range(N):\n",
    "    Pi = P[i]\n",
    "    for j in range(i+1, N):\n",
    "        Pj = P[j]\n",
    "        E[i,j] = 1/(Pi**-1 + Pj**-1 -1)\n",
    "        E[j,i] = E[i,j]\n",
    "\n",
    "M = js - E\n",
    "        \n",
    "fig = plt.figure(figsize=(8,24))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.imshow(js[srt,:][:,srt])\n",
    "ax1.set_title('Jaccard Similarity')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.imshow(E[srt,:][:,srt])\n",
    "ax2.set_title('Expected Similarity')\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.imshow(M[srt,:][:,srt])\n",
    "ax3.set_title('Residual Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pynndescent\n",
    "\n",
    "index = NNDescent(data.T, metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mNNDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric_kwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleaf_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpruning_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtree_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m'numpy.random'\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m'/home/camiel/anaconda3/envs/chromograph/lib/python3.7/site-packages/numpy/random/__init__.py'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed_per_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "NNDescent for fast approximate nearest neighbor queries. NNDescent is\n",
       "very flexible and supports a wide variety of distances, including\n",
       "non-metric distances. NNDescent also scales well against high dimensional\n",
       "data in many cases. This implementation provides a straightfoward\n",
       "interface, with access to some tuning parameters.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: array os shape (n_samples, n_features)\n",
       "    The training data set to find nearest neighbors in.\n",
       "\n",
       "metric: string or callable (optional, default='euclidean')\n",
       "    The metric to use for computing nearest neighbors. If a callable is\n",
       "    used it must be a numba njit compiled function. Supported metrics\n",
       "    include:\n",
       "        * euclidean\n",
       "        * manhattan\n",
       "        * chebyshev\n",
       "        * minkowski\n",
       "        * canberra\n",
       "        * braycurtis\n",
       "        * mahalanobis\n",
       "        * wminkowski\n",
       "        * seuclidean\n",
       "        * cosine\n",
       "        * correlation\n",
       "        * haversine\n",
       "        * hamming\n",
       "        * jaccard\n",
       "        * dice\n",
       "        * russelrao\n",
       "        * kulsinski\n",
       "        * rogerstanimoto\n",
       "        * sokalmichener\n",
       "        * sokalsneath\n",
       "        * yule\n",
       "    Metrics that take arguments (such as minkowski, mahalanobis etc.)\n",
       "    can have arguments passed via the metric_kwds dictionary. At this\n",
       "    time care must be taken and dictionary elements must be ordered\n",
       "    appropriately; this will hopefully be fixed in the future.\n",
       "\n",
       "metric_kwds: dict (optional, default {})\n",
       "    Arguments to pass on to the metric, such as the ``p`` value for\n",
       "    Minkowski distance.\n",
       "\n",
       "n_neighbors: int (optional, default=15)\n",
       "    The number of neighbors to use in k-neighbor graph data structure\n",
       "    used for fast approximate nearest neighbor search. Larger values\n",
       "    will result in more accurate search results at the cost of\n",
       "    computation time.\n",
       "\n",
       "n_trees: int (optional, default=None)\n",
       "    This implementation uses random projection forests for initialization\n",
       "    of searches. This parameter controls the number of trees in that\n",
       "    forest. A larger number will result in more accurate neighbor\n",
       "    computation at the cost of performance. The default of None means\n",
       "    a value will be chosen based on the size of the data.\n",
       "\n",
       "leaf_size: int (optional, default=None)\n",
       "    The maximum number of points in a leaf for the random projection trees.\n",
       "    The default of None means a value will be chosen based on n_neighbors.\n",
       "\n",
       "pruning_level: int (optional, default=0)\n",
       "    How aggressively to prune the graph. Higher values perform more\n",
       "    aggressive pruning, resulting in faster search with lower accuracy.\n",
       "\n",
       "tree_init: bool (optional, default=True)\n",
       "    Whether to use random projection trees for initialization.\n",
       "\n",
       "random_state: int, RandomState instance or None, optional (default: None)\n",
       "    If int, random_state is the seed used by the random number generator;\n",
       "    If RandomState instance, random_state is the random number generator;\n",
       "    If None, the random number generator is the RandomState instance used\n",
       "    by `np.random`.\n",
       "\n",
       "algorithm: string (optional, default='standard')\n",
       "    This implementation provides an alternative algorithm for\n",
       "    construction of the k-neighbors graph used as a search index. The\n",
       "    alternative algorithm can be fast for large ``n_neighbors`` values.\n",
       "    To use the alternative algorithm specify ``'alternative'``.\n",
       "\n",
       "low_memory: boolean (optional, default=False)\n",
       "    Whether to use a lower memory, but more computationally expensive\n",
       "    approach to index construction. This defaults to false as for most\n",
       "    cases it speeds index construction, but if you are having issues\n",
       "    with excessive memory use for your dataset consider setting this\n",
       "    to True.\n",
       "\n",
       "max_candidates: int (optional, default=20)\n",
       "    Internally each \"self-join\" keeps a maximum number of candidates (\n",
       "    nearest neighbors and reverse nearest neighbors) to be considered.\n",
       "    This value controls this aspect of the algorithm. Larger values will\n",
       "    provide more accurate search results later, but potentially at\n",
       "    non-negligible computation cost in building the index. Don't tweak\n",
       "    this value unless you know what you're doing.\n",
       "\n",
       "n_iters: int (optional, default=None)\n",
       "    The maximum number of NN-descent iterations to perform. The\n",
       "    NN-descent algorithm can abort early if limited progress is being\n",
       "    made, so this only controls the worst case. Don't tweak\n",
       "    this value unless you know what you're doing. The default of None means\n",
       "    a value will be chosen based on the size of the data.\n",
       "\n",
       "delta: float (optional, default=0.001)\n",
       "    Controls the early abort due to limited progress. Larger values\n",
       "    will result in earlier aborts, providing less accurate indexes,\n",
       "    and less accurate searching. Don't tweak this value unless you know\n",
       "    what you're doing.\n",
       "\n",
       "rho: float (optional, default=0.5)\n",
       "    Controls the random sampling of potential candidates in any given\n",
       "    iteration of NN-descent. Larger values will result in less accurate\n",
       "    indexes and less accurate searching. Don't tweak this value unless\n",
       "    you know what you're doing.\n",
       "\n",
       "n_jobs: int or None, optional (default=None)\n",
       "    The number of parallel jobs to run for neighbors index construction.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors.\n",
       "\n",
       "verbose: bool (optional, default=False)\n",
       "    Whether to print status data during the computation.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/chromograph/lib/python3.7/site-packages/pynndescent/pynndescent_.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?NNDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sparse jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0 ... 566822 566822 566822]\n"
     ]
    }
   ],
   "source": [
    "spm = ds.layers['5kb_bins'].sparse(rows = bins)\n",
    "\n",
    "rows = spm.row\n",
    "cols = spm.col\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "12606 79466\n",
      "0.1586338811567211\n",
      "512 ms ± 18.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "v1 = rows[cols==0]\n",
    "v2 = rows[cols==1]\n",
    "\n",
    "pqr = len(np.unique(np.concatenate((v1,v2))))\n",
    "p = (len(np.unique(v1)) + len(np.unique(v2))) - pqr\n",
    "print(p, pqr)\n",
    "print(p/pqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4de0f046355f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac_sim_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@njit()\n",
    "def jac_sim_sparse(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    ## Total features\n",
    "    pqr = len(np.unique(np.concatenate((v1,v2))))\n",
    "    \n",
    "    ## overlap\n",
    "    p = (len(np.unique(v1)) + len(np.unique(v2))) - pqr\n",
    "    \n",
    "    return p/pqr\n",
    "\n",
    "t = []\n",
    "for x in range(5):\n",
    "    start = time.time()\n",
    "\n",
    "    N = 100\n",
    "    srt = ds.ca['Clusters'][:N].argsort()\n",
    "\n",
    "    js = np.zeros([N,N])\n",
    "\n",
    "    for i in range(N):\n",
    "        v1 = rows[cols==i]\n",
    "        for j in range(i+1, N):\n",
    "            v2 = rows[cols==j]\n",
    "            js[i,j] = jac_sim_sparse(v1,v2)\n",
    "            js[j,i] =  js[i,j]\n",
    "\n",
    "#     plt.imshow(js[srt,:][:,srt])\n",
    "\n",
    "    t.append(time.time() - start)\n",
    "    print(time.time() - start)\n",
    "plt.imshow(js[srt,:][:,srt])    \n",
    "print(f'mean {np.mean(t)} with st. dev: {np.std(t)}')\n",
    "print(js[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-24a4806558fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac_sim_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def jac_sim_sparse(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    ## Total features\n",
    "    pqr = len(set(np.concatenate((v1,v2))))\n",
    "    \n",
    "    ## overlap\n",
    "    p = (len(set(v1)) + len(set(v2))) - pqr\n",
    "\n",
    "    return p/pqr\n",
    "\n",
    "t = []\n",
    "for x in range(5):\n",
    "    start = time.time()\n",
    "\n",
    "    N = 100\n",
    "    srt = ds.ca['Clusters'][:N].argsort()\n",
    "\n",
    "    js = np.zeros([N,N])\n",
    "\n",
    "    for i in range(N):\n",
    "        v1 = rows[cols==i]\n",
    "        for j in range(i+1, N):\n",
    "            v2 = rows[cols==j]\n",
    "            js[i,j] = jac_sim_sparse(v1,v2)\n",
    "            js[j,i] =  js[i,j]\n",
    "\n",
    "#     plt.imshow(js[srt,:][:,srt])\n",
    "\n",
    "    t.append(time.time() - start)\n",
    "    print(time.time() - start)\n",
    "plt.imshow(js[srt,:][:,srt])    \n",
    "print(f'mean {np.mean(t)} with st. dev: {np.std(t)}')\n",
    "print(js[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(js), np.min(js))\n",
    "print(np.max(E), np.min(E))\n",
    "print(np.max(M), np.min(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p as the number of variables that are positive in both vectors  \n",
    "q as the number of variables that are positive in the first and negative in the second  \n",
    "r as the number of variables that are negative in the first and positive in the second  \n",
    "s as the number of variables that are negative in both  \n",
    "t as the total number of variables (which is also p+q+r+s, as those are all exclusive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chromograph (py3.7)",
   "language": "python",
   "name": "chromograph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
